{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "portfolio-intro",
   "metadata": {},
   "source": [
    "# Portfolio Optimization: Modern Portfolio Theory Implementation\n",
    "\n",
    "## From Statistical Analysis to Investment Decisions\n",
    "\n",
    "This notebook implements **Modern Portfolio Theory (MPT)** using our statistical findings to construct optimal portfolios.\n",
    "\n",
    "### What We'll Build:\n",
    "1. **Efficient Frontier**: Risk-return trade-off visualization\n",
    "2. **Optimal Portfolios**: Maximum Sharpe, Minimum Variance\n",
    "3. **Risk-Parity Portfolio**: Equal risk contribution\n",
    "4. **Performance Backtesting**: Historical validation\n",
    "5. **Portfolio Analytics**: Comprehensive risk metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-libraries-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot styling\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ“ Portfolio optimization libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-previous-results",
   "metadata": {},
   "source": [
    "## Load Previous Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from previous analysis\n",
    "tickers = [\"IVV\", \"IEF\", \"GLD\"]\n",
    "\n",
    "# Load returns\n",
    "path = '../data/sample_data.csv'\n",
    "data = pd.read_csv(path, index_col=0, parse_dates=True, header=[0, 1])\n",
    "price = pd.DataFrame({t: data[t]['Close'] for t in tickers})\n",
    "log_returns = np.log(price / price.shift(1)).dropna()\n",
    "\n",
    "# Load statistical results\n",
    "stat_results = pd.read_csv('../data/statistical_results.csv', index_col=0)\n",
    "risk_summary = pd.read_csv('../data/risk_summary.csv', index_col=0)\n",
    "\n",
    "print(f\"Data loaded: {log_returns.shape[0]} trading days\")\n",
    "print(f\"Date range: {log_returns.index[0].date()} to {log_returns.index[-1].date()}\")\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(risk_summary.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-portfolio-theory",
   "metadata": {},
   "source": [
    "## 1. Modern Portfolio Theory Foundations\n",
    "\n",
    "### Key Equations:\n",
    "1. **Portfolio Return**: \\(R_p = \\sum w_i R_i\\)\n",
    "2. **Portfolio Variance**: \\(\\sigma_p^2 = \\sum \\sum w_i w_j \\sigma_{ij}\\)\n",
    "3. **Sharpe Ratio**: \\(S = \\frac{R_p - R_f}{\\sigma_p}\\)\n",
    "\n",
    "Where:\n",
    "- \\(w_i\\) = weight of asset i\n",
    "- \\(R_i\\) = return of asset i\n",
    "- \\(\\sigma_{ij}\\) = covariance between assets i and j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portfolio-calculations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate inputs for portfolio optimization\n",
    "def calculate_portfolio_stats(weights, returns, cov_matrix, risk_free_rate=0.02):\n",
    "    \"\"\"Calculate portfolio statistics given weights\"\"\"\n",
    "    # Annualization factor\n",
    "    days_per_year = 252\n",
    "    \n",
    "    # Portfolio return\n",
    "    port_return = np.sum(returns.mean() * weights) * days_per_year\n",
    "    \n",
    "    # Portfolio volatility\n",
    "    port_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix * days_per_year, weights)))\n",
    "    \n",
    "    # Sharpe ratio\n",
    "    sharpe = (port_return - risk_free_rate) / port_vol if port_vol > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'return': port_return,\n",
    "        'volatility': port_vol,\n",
    "        'sharpe': sharpe\n",
    "    }\n",
    "\n",
    "# Get inputs\n",
    "expected_returns = log_returns.mean() * 252  # Annualized\n",
    "cov_matrix = log_returns.cov() * 252  # Annualized covariance\n",
    "\n",
    "print(\"Annualized Expected Returns:\")\n",
    "print(expected_returns.round(4))\n",
    "print(\"\\nAnnualized Covariance Matrix:\")\n",
    "print(cov_matrix.round(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-frontier",
   "metadata": {},
   "source": [
    "## 2. Efficient Frontier Calculation\n",
    "\n",
    "The **Efficient Frontier** shows the set of optimal portfolios that offer:\n",
    "- Highest expected return for a given level of risk\n",
    "- Lowest risk for a given level of expected return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-random-portfolios",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_portfolios(num_portfolios, returns, cov_matrix, risk_free_rate=0.02):\n",
    "    \"\"\"Generate random portfolios for efficient frontier\"\"\"\n",
    "    results = np.zeros((3, num_portfolios))\n",
    "    weights_record = []\n",
    "    \n",
    "    for i in range(num_portfolios):\n",
    "        # Generate random weights (sum to 1)\n",
    "        weights = np.random.random(len(tickers))\n",
    "        weights /= np.sum(weights)\n",
    "        weights_record.append(weights)\n",
    "        \n",
    "        # Calculate portfolio statistics\n",
    "        port_stats = calculate_portfolio_stats(weights, returns, cov_matrix, risk_free_rate)\n",
    "        \n",
    "        results[0, i] = port_stats['volatility']\n",
    "        results[1, i] = port_stats['return']\n",
    "        results[2, i] = port_stats['sharpe']\n",
    "    \n",
    "    return results, weights_record\n",
    "\n",
    "# Generate 10,000 random portfolios\n",
    "num_portfolios = 10000\n",
    "results, weights = generate_random_portfolios(num_portfolios, log_returns, cov_matrix)\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "portfolios = pd.DataFrame({\n",
    "    'Volatility': results[0],\n",
    "    'Return': results[1],\n",
    "    'Sharpe': results[2]\n",
    "})\n",
    "\n",
    "print(f\"Generated {num_portfolios:,} random portfolios\")\n",
    "print(\"\\nPortfolio Statistics Summary:\")\n",
    "print(portfolios.describe().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-efficient-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Efficient Frontier\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot 1: Efficient Frontier with individual assets\n",
    "scatter = axes[0].scatter(portfolios['Volatility'], portfolios['Return'], \n",
    "                         c=portfolios['Sharpe'], cmap='viridis', \n",
    "                         alpha=0.6, s=10, label='Random Portfolios')\n",
    "\n",
    "# Plot individual assets\n",
    "for idx, ticker in enumerate(tickers):\n",
    "    axes[0].scatter(np.sqrt(cov_matrix.iloc[idx, idx]), expected_returns.iloc[idx], \n",
    "                   s=200, marker='*', edgecolors='black', linewidth=2, \n",
    "                   label=f'{ticker} (100%)', zorder=5)\n",
    "\n",
    "axes[0].set_xlabel('Annual Volatility (Risk)')\n",
    "axes[0].set_ylabel('Annual Return')\n",
    "axes[0].set_title('Efficient Frontier & Individual Assets', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(loc='upper left')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add colorbar for Sharpe ratio\n",
    "cbar = plt.colorbar(scatter, ax=axes[0])\n",
    "cbar.set_label('Sharpe Ratio', rotation=270, labelpad=15)\n",
    "\n",
    "# Plot 2: Sharpe ratio distribution\n",
    "axes[1].hist(portfolios['Sharpe'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=portfolios['Sharpe'].max(), color='red', linestyle='--', \n",
    "                label=f\"Max Sharpe: {portfolios['Sharpe'].max():.3f}\")\n",
    "axes[1].set_xlabel('Sharpe Ratio')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Sharpe Ratio Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimal-portfolios",
   "metadata": {},
   "source": [
    "## ðŸ† 3. Finding Optimal Portfolios\n",
    "\n",
    "We'll find three key portfolios:\n",
    "1. **Maximum Sharpe Ratio** (Tangency Portfolio)\n",
    "2. **Minimum Variance** (Safest Portfolio)\n",
    "3. **Equal-Weighted** (Naive Diversification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimization-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization functions\n",
    "def portfolio_volatility(weights, cov_matrix):\n",
    "    return np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "\n",
    "def portfolio_return(weights, expected_returns):\n",
    "    return np.dot(weights, expected_returns)\n",
    "\n",
    "def negative_sharpe_ratio(weights, expected_returns, cov_matrix, risk_free_rate):\n",
    "    port_return = portfolio_return(weights, expected_returns)\n",
    "    port_vol = portfolio_volatility(weights, cov_matrix)\n",
    "    return -(port_return - risk_free_rate) / port_vol if port_vol > 0 else 1e6\n",
    "\n",
    "# Constraints: weights sum to 1, no short selling\n",
    "constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "bounds = tuple((0, 1) for _ in range(len(tickers)))\n",
    "\n",
    "# Initial guess (equal weights)\n",
    "init_guess = [1/len(tickers)] * len(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calculate-optimal-portfolios",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Maximum Sharpe Ratio Portfolio\n",
    "max_sharpe_result = minimize(\n",
    "    negative_sharpe_ratio,\n",
    "    init_guess,\n",
    "    args=(expected_returns, cov_matrix, 0.02),\n",
    "    method='SLSQP',\n",
    "    bounds=bounds,\n",
    "    constraints=constraints\n",
    ")\n",
    "\n",
    "# 2. Minimum Variance Portfolio\n",
    "min_vol_result = minimize(\n",
    "    portfolio_volatility,\n",
    "    init_guess,\n",
    "    args=(cov_matrix,),\n",
    "    method='SLSQP',\n",
    "    bounds=bounds,\n",
    "    constraints=constraints\n",
    ")\n",
    "\n",
    "# 3. Equal-Weighted Portfolio\n",
    "equal_weights = np.array([1/len(tickers)] * len(tickers))\n",
    "\n",
    "# Calculate statistics for each portfolio\n",
    "portfolios_dict = {\n",
    "    'Max Sharpe': max_sharpe_result.x,\n",
    "    'Min Volatility': min_vol_result.x,\n",
    "    'Equal Weight': equal_weights\n",
    "}\n",
    "\n",
    "# Create summary table\n",
    "portfolio_summary = []\n",
    "\n",
    "for name, weights in portfolios_dict.items():\n",
    "    stats = calculate_portfolio_stats(weights, log_returns, cov_matrix)\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    # Maximum Drawdown (simplified)\n",
    "    port_returns = (log_returns * weights).sum(axis=1)\n",
    "    cumulative = (1 + port_returns).cumprod()\n",
    "    running_max = cumulative.expanding().max()\n",
    "    drawdown = (cumulative - running_max) / running_max\n",
    "    max_dd = drawdown.min()\n",
    "    \n",
    "    portfolio_summary.append({\n",
    "        'Portfolio': name,\n",
    "        'IVV %': f\"{weights[0]*100:.1f}%\",\n",
    "        'IEF %': f\"{weights[1]*100:.1f}%\",\n",
    "        'GLD %': f\"{weights[2]*100:.1f}%\",\n",
    "        'Return %': f\"{stats['return']*100:.2f}%\",\n",
    "        'Volatility %': f\"{stats['volatility']*100:.2f}%\",\n",
    "        'Sharpe Ratio': f\"{stats['sharpe']:.3f}\",\n",
    "        'Max Drawdown %': f\"{max_dd*100:.2f}%\"\n",
    "    })\n",
    "\n",
    "portfolio_df = pd.DataFrame(portfolio_summary)\n",
    "print(\"OPTIMAL PORTFOLIOS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(portfolio_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-optimal-portfolios",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize portfolio weights\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "for idx, (name, weights) in enumerate(portfolios_dict.items()):\n",
    "    axes[idx].pie(weights, labels=tickers, colors=colors, autopct='%1.1f%%', \n",
    "                 startangle=90, wedgeprops={'edgecolor': 'white', 'linewidth': 2})\n",
    "    stats = calculate_portfolio_stats(weights, log_returns, cov_matrix)\n",
    "    axes[idx].set_title(f'{name}\\nReturn: {stats[\"return\"]*100:.2f}% | ' +\n",
    "                       f'Risk: {stats[\"volatility\"]*100:.2f}%\\n' +\n",
    "                       f'Sharpe: {stats[\"sharpe\"]:.3f}', \n",
    "                       fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "risk-parity-portfolio",
   "metadata": {},
   "source": [
    "## 4. Risk Parity Portfolio\n",
    "\n",
    "**Risk Parity** allocates based on risk contribution rather than capital allocation. Each asset contributes equally to portfolio risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calculate-risk-parity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_risk_contribution(weights, cov_matrix):\n",
    "    \"\"\"Calculate risk contribution of each asset\"\"\"\n",
    "    port_vol = portfolio_volatility(weights, cov_matrix)\n",
    "    marginal_risk = np.dot(cov_matrix, weights) / port_vol\n",
    "    risk_contribution = weights * marginal_risk\n",
    "    return risk_contribution / port_vol  # Percentage contribution\n",
    "\n",
    "def risk_parity_objective(weights, cov_matrix):\n",
    "    \"\"\"Objective: equal risk contribution\"\"\"\n",
    "    n = len(weights)\n",
    "    target_risk = np.ones(n) / n  # Equal risk contribution\n",
    "    actual_risk = calculate_risk_contribution(weights, cov_matrix)\n",
    "    return np.sum((actual_risk - target_risk) ** 2)\n",
    "\n",
    "# Optimize for risk parity\n",
    "risk_parity_result = minimize(\n",
    "    risk_parity_objective,\n",
    "    init_guess,\n",
    "    args=(cov_matrix,),\n",
    "    method='SLSQP',\n",
    "    bounds=bounds,\n",
    "    constraints=constraints\n",
    ")\n",
    "\n",
    "risk_parity_weights = risk_parity_result.x\n",
    "risk_contributions = calculate_risk_contribution(risk_parity_weights, cov_matrix)\n",
    "\n",
    "# Display results\n",
    "print(\"RISK PARITY PORTFOLIO ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nPortfolio Weights:\")\n",
    "for ticker, weight in zip(tickers, risk_parity_weights):\n",
    "    print(f\"  {ticker}: {weight*100:.1f}%\")\n",
    "\n",
    "print(\"\\nRisk Contributions (Target: 33.3% each):\")\n",
    "for ticker, contribution in zip(tickers, risk_contributions):\n",
    "    print(f\"  {ticker}: {contribution*100:.1f}%\")\n",
    "\n",
    "# Calculate portfolio statistics\n",
    "rp_stats = calculate_portfolio_stats(risk_parity_weights, log_returns, cov_matrix)\n",
    "print(f\"\\nRisk Parity Portfolio Performance:\")\n",
    "print(f\"  Return: {rp_stats['return']*100:.2f}%\")\n",
    "print(f\"  Volatility: {rp_stats['volatility']*100:.2f}%\")\n",
    "print(f\"  Sharpe Ratio: {rp_stats['sharpe']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backtesting-performance",
   "metadata": {},
   "source": [
    "## 5. Portfolio Performance Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backtest-portfolios",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtest portfolio performance\n",
    "def backtest_portfolio(weights, returns, initial_capital=10000):\n",
    "    \"\"\"Backtest portfolio with given weights\"\"\"\n",
    "    # Calculate portfolio returns\n",
    "    portfolio_returns = (returns * weights).sum(axis=1)\n",
    "    \n",
    "    # Calculate equity curve\n",
    "    equity = initial_capital * (1 + portfolio_returns).cumprod()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    total_return = (equity.iloc[-1] / initial_capital) - 1\n",
    "    \n",
    "    # Annualized metrics\n",
    "    years = len(returns) / 252\n",
    "    cagr = (1 + total_return) ** (1/years) - 1\n",
    "    \n",
    "    # Maximum drawdown\n",
    "    running_max = equity.expanding().max()\n",
    "    drawdown = (equity - running_max) / running_max\n",
    "    max_dd = drawdown.min()\n",
    "    \n",
    "    # Volatility (annualized)\n",
    "    vol = portfolio_returns.std() * np.sqrt(252)\n",
    "    \n",
    "    return {\n",
    "        'equity': equity,\n",
    "        'returns': portfolio_returns,\n",
    "        'total_return': total_return,\n",
    "        'cagr': cagr,\n",
    "        'volatility': vol,\n",
    "        'max_drawdown': max_dd,\n",
    "        'sharpe': (cagr - 0.02) / vol if vol > 0 else 0\n",
    "    }\n",
    "\n",
    "# Backtest all portfolios\n",
    "backtest_results = {}\n",
    "portfolios_to_test = {\n",
    "    'Max Sharpe': max_sharpe_result.x,\n",
    "    'Min Volatility': min_vol_result.x,\n",
    "    'Equal Weight': equal_weights,\n",
    "    'Risk Parity': risk_parity_weights\n",
    "}\n",
    "\n",
    "for name, weights in portfolios_to_test.items():\n",
    "    backtest_results[name] = backtest_portfolio(weights, log_returns)\n",
    "\n",
    "# Compare performance\n",
    "comparison_data = []\n",
    "\n",
    "for name, results in backtest_results.items():\n",
    "    comparison_data.append({\n",
    "        'Portfolio': name,\n",
    "        'CAGR %': f\"{results['cagr']*100:.2f}%\",\n",
    "        'Total Return %': f\"{results['total_return']*100:.2f}%\",\n",
    "        'Volatility %': f\"{results['volatility']*100:.2f}%\",\n",
    "        'Max DD %': f\"{results['max_drawdown']*100:.2f}%\",\n",
    "        'Sharpe Ratio': f\"{results['sharpe']:.3f}\"\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nBACKTESTING RESULTS (Full History)\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-backtest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot equity curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (name, results) in enumerate(backtest_results.items()):\n",
    "    if idx < 4:  # We have 4 portfolios\n",
    "        axes[idx].plot(results['equity'].index, results['equity'], \n",
    "                      linewidth=2, label=name)\n",
    "        axes[idx].set_title(f'{name} Portfolio', fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_ylabel('Portfolio Value ($)')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "        axes[idx].legend(loc='upper left')\n",
    "        \n",
    "        # Add final value annotation\n",
    "        final_val = results['equity'].iloc[-1]\n",
    "        axes[idx].annotate(f'Final: ${final_val:,.0f}', \n",
    "                          xy=(results['equity'].index[-1], final_val),\n",
    "                          xytext=(-100, 20), textcoords='offset points',\n",
    "                          arrowprops=dict(arrowstyle='->'),\n",
    "                          fontsize=9, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Combined equity curve\n",
    "plt.figure(figsize=(12, 6))\n",
    "for name, results in backtest_results.items():\n",
    "    plt.plot(results['equity'].index, results['equity'], \n",
    "             linewidth=2, label=name, alpha=0.8)\n",
    "\n",
    "# Add individual assets for comparison\n",
    "for ticker in tickers:\n",
    "    asset_equity = 10000 * (1 + log_returns[ticker]).cumprod()\n",
    "    plt.plot(asset_equity.index, asset_equity, '--', \n",
    "             linewidth=1, label=f'{ticker} (100%)', alpha=0.5)\n",
    "\n",
    "plt.title('Portfolio Performance Comparison ($10,000 Initial Investment)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Portfolio Value ($)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolling-performance",
   "metadata": {},
   "source": [
    "## 6. Rolling Portfolio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolling-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze rolling performance\n",
    "def calculate_rolling_sharpe(returns, window=252, risk_free_rate=0.02):\n",
    "    \"\"\"Calculate rolling Sharpe ratio\"\"\"\n",
    "    excess_returns = returns - risk_free_rate/252\n",
    "    rolling_mean = excess_returns.rolling(window).mean() * 252\n",
    "    rolling_std = returns.rolling(window).std() * np.sqrt(252)\n",
    "    rolling_sharpe = rolling_mean / rolling_std\n",
    "    return rolling_sharpe\n",
    "\n",
    "# Calculate rolling Sharpe for each portfolio\n",
    "rolling_windows = [126, 252, 504]  # 6 months, 1 year, 2 years\n",
    "\n",
    "fig, axes = plt.subplots(len(rolling_windows), 1, figsize=(14, 10))\n",
    "\n",
    "for idx, window in enumerate(rolling_windows):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    for name, results in backtest_results.items():\n",
    "        rolling_sharpe = calculate_rolling_sharpe(results['returns'], window)\n",
    "        ax.plot(rolling_sharpe.index, rolling_sharpe, \n",
    "                linewidth=1.5, label=name, alpha=0.8)\n",
    "    \n",
    "    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5, alpha=0.5)\n",
    "    ax.axhline(y=1, color='green', linestyle='--', linewidth=1, alpha=0.5, label='Sharpe = 1')\n",
    "    \n",
    "    ax.set_title(f'{window}-Day Rolling Sharpe Ratio', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Sharpe Ratio')\n",
    "    ax.legend(loc='upper left', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitivity-analysis",
   "metadata": {},
   "source": [
    "## 7. Sensitivity Analysis & Robustness Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitivity-tests",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different time periods\n",
    "periods = {\n",
    "    'Full History': (log_returns.index[0], log_returns.index[-1]),\n",
    "    'Pre-2008 Crisis': (log_returns.index[0], pd.Timestamp('2007-12-31')),\n",
    "    'Post-2008 Recovery': (pd.Timestamp('2009-01-01'), pd.Timestamp('2019-12-31')),\n",
    "    'Recent Years': (pd.Timestamp('2020-01-01'), log_returns.index[-1])\n",
    "}\n",
    "\n",
    "period_results = []\n",
    "\n",
    "for period_name, (start_date, end_date) in periods.items():\n",
    "    # Filter data for period\n",
    "    mask = (log_returns.index >= start_date) & (log_returns.index <= end_date)\n",
    "    period_returns = log_returns[mask]\n",
    "    \n",
    "    if len(period_returns) > 252:  # Require at least 1 year of data\n",
    "        # Recalculate inputs for this period\n",
    "        period_exp_returns = period_returns.mean() * 252\n",
    "        period_cov = period_returns.cov() * 252\n",
    "        \n",
    "        # Calculate max Sharpe portfolio for this period\n",
    "        result = minimize(\n",
    "            negative_sharpe_ratio,\n",
    "            init_guess,\n",
    "            args=(period_exp_returns, period_cov, 0.02),\n",
    "            method='SLSQP',\n",
    "            bounds=bounds,\n",
    "            constraints=constraints\n",
    "        )\n",
    "        \n",
    "        # Calculate statistics\n",
    "        stats = calculate_portfolio_stats(result.x, period_returns, period_cov)\n",
    "        \n",
    "        period_results.append({\n",
    "            'Period': period_name,\n",
    "            'Start': start_date.date(),\n",
    "            'End': end_date.date(),\n",
    "            'Days': len(period_returns),\n",
    "            'IVV %': f\"{result.x[0]*100:.1f}%\",\n",
    "            'IEF %': f\"{result.x[1]*100:.1f}%\",\n",
    "            'GLD %': f\"{result.x[2]*100:.1f}%\",\n",
    "            'Return %': f\"{stats['return']*100:.2f}%\",\n",
    "            'Sharpe': f\"{stats['sharpe']:.3f}\"\n",
    "        })\n",
    "\n",
    "sensitivity_df = pd.DataFrame(period_results)\n",
    "print(\"SENSITIVITY ANALYSIS: Portfolio Performance Across Different Periods\")\n",
    "print(\"=\"*90)\n",
    "print(sensitivity_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-recommendations",
   "metadata": {},
   "source": [
    "## ðŸ“‹ 8. Conclusions & Investment Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-recommendations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final recommendations\n",
    "print(\"=\"*80)\n",
    "print(\"PORTFOLIO OPTIMIZATION: FINAL RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Identify best portfolio based on different objectives\n",
    "best_sharpe = comparison_df.loc[comparison_df['Sharpe Ratio'].str.replace('.', '', 1).str.isnumeric()]\n",
    "best_sharpe = best_sharpe.loc[best_sharpe['Sharpe Ratio'].astype(float).idxmax()]\n",
    "\n",
    "best_drawdown = comparison_df.loc[comparison_df['Max DD %'].str.replace('.', '', 1).str.replace('%', '').str.isnumeric()]\n",
    "best_drawdown = best_drawdown.loc[best_drawdown['Max DD %'].str.replace('%', '').astype(float).idxmax()]\n",
    "\n",
    "print(\"\\n TOP PERFORMERS BY METRIC:\")\n",
    "print(f\"1. Best Risk-Adjusted Return (Sharpe): {best_sharpe['Portfolio']} (Sharpe: {best_sharpe['Sharpe Ratio']})\")\n",
    "print(f\"2. Best Drawdown Protection: {best_drawdown['Portfolio']} (Max DD: {best_drawdown['Max DD %']})\")\n",
    "\n",
    "# Extract optimal weights\n",
    "optimal_weights = portfolios_dict['Max Sharpe']\n",
    "print(f\"\\n RECOMMENDED PORTFOLIO (Maximum Sharpe Ratio):\")\n",
    "for ticker, weight in zip(tickers, optimal_weights):\n",
    "    print(f\"  â€¢ {ticker}: {weight*100:.1f}%\")\n",
    "\n",
    "print(\"\\n EXPECTED PERFORMANCE (Annualized):\")\n",
    "max_sharpe_stats = calculate_portfolio_stats(optimal_weights, log_returns, cov_matrix)\n",
    "print(f\"  â€¢ Expected Return: {max_sharpe_stats['return']*100:.2f}%\")\n",
    "print(f\"  â€¢ Expected Volatility: {max_sharpe_stats['volatility']*100:.2f}%\")\n",
    "print(f\"  â€¢ Sharpe Ratio: {max_sharpe_stats['sharpe']:.3f}\")\n",
    "\n",
    "print(\"\\n DIVERSIFICATION BENEFITS:\")\n",
    "# Calculate portfolio vs individual risk\n",
    "individual_vols = np.sqrt(np.diag(cov_matrix))\n",
    "portfolio_vol = max_sharpe_stats['volatility']\n",
    "print(f\"  â€¢ Weighted Avg Individual Vol: {np.dot(individual_vols, optimal_weights)*100:.2f}%\")\n",
    "print(f\"  â€¢ Portfolio Volatility: {portfolio_vol*100:.2f}%\")\n",
    "print(f\"  â€¢ Diversification Benefit: {(np.dot(individual_vols, optimal_weights) - portfolio_vol)*100:.2f}% reduction\")\n",
    "\n",
    "print(\"\\n RISK CONSIDERATIONS:\")\n",
    "print(\"  1. Historical analysis doesn't guarantee future performance\")\n",
    "print(\"  2. Assumes normal market conditions (no black swan events)\")\n",
    "print(\"  3. Ignores transaction costs and taxes\")\n",
    "print(\"  4. Assumes constant correlations (which we know vary over time)\")\n",
    "\n",
    "print(\"\\n IMPLEMENTATION SUGGESTIONS:\")\n",
    "print(\"  1. Start with equal-weighted portfolio as baseline\")\n",
    "print(\"  2. Gradually tilt toward optimal weights\")\n",
    "print(\"  3. Rebalance quarterly to maintain target weights\")\n",
    "print(\"  4. Monitor correlations and adjust if market regime changes\")\n",
    "\n",
    "print(\"\\n NEXT STEPS FOR PROJECT:\")\n",
    "print(\"  1. Implement GARCH volatility forecasting\")\n",
    "print(\"  2. Add Monte Carlo simulation for uncertainty\")\n",
    "print(\"  3. Integrate with SQL database for results storage\")\n",
    "print(\"  4. Create Power BI dashboard for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-results-portfolio",
   "metadata": {},
   "source": [
    "## Save Results for Future Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-portfolio-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all portfolio results\n",
    "portfolio_results = {\n",
    "    'optimal_weights': pd.DataFrame({\n",
    "        'Portfolio': list(portfolios_dict.keys()) + ['Risk Parity'],\n",
    "        'IVV': list([w[0] for w in portfolios_dict.values()]) + [risk_parity_weights[0]],\n",
    "        'IEF': list([w[1] for w in portfolios_dict.values()]) + [risk_parity_weights[1]],\n",
    "        'GLD': list([w[2] for w in portfolios_dict.values()]) + [risk_parity_weights[2]]\n",
    "    }),\n",
    "    'performance_summary': portfolio_df,\n",
    "    'backtest_results': comparison_df,\n",
    "    'sensitivity_analysis': sensitivity_df\n",
    "}\n",
    "\n",
    "# Save to CSV\n",
    "portfolio_results['optimal_weights'].to_csv('../data/portfolio_weights.csv', index=False)\n",
    "portfolio_results['performance_summary'].to_csv('../data/portfolio_performance.csv', index=False)\n",
    "portfolio_results['backtest_results'].to_csv('../data/backtest_results.csv', index=False)\n",
    "\n",
    "print(\"âœ“ Portfolio results saved to '../data/' folder\")\n",
    "print(\"\\n PORTFOLIO OPTIMIZATION COMPLETE!\")\n",
    "print(\"\\nKey insights have been generated and saved.\")\n",
    "print(\"Next: Implement SQL integration and create Power BI dashboard.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
